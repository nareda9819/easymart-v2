# Easymart Chatbot - Comprehensive Technical Documentation

## 1. Project Overview
Easymart Chatbot is a specialized conversational AI designed for an e-commerce furniture store. It goes beyond simple FAQ bots by implementing a **Retrieval-Augmented Generation (RAG)** architecture. It understands user intent, searches a product catalog using hybrid techniques, and maintains conversation context to handle complex queries like "Show me office chairs" followed by "add the first one to my cart".

---

## 2. Technology Stack

### Core Framework
*   **Python 3.11**: Chosen for its robust ecosystem in AI and data processing.
*   **FastAPI**: High-performance web framework used for the REST API. It provides automatic OpenAPI documentation and native async support, crucial for handling concurrent LLM and database requests.
*   **Pydantic**: Used for strict data validation and settings management.

### Search & Retrieval (The "Brain")
*   **ChromaDB**: An open-source embedding database. It stores vector representations of product descriptions, allowing the system to understand semantic similarity (e.g., "seat" is related to "chair").
*   **RankBM25**: A probabilistic information retrieval algorithm. It handles exact keyword matching, ensuring that if a user searches for a specific model number or term, it is found even if the semantic meaning is vague.
*   **Sentence-Transformers (all-MiniLM-L6-v2)**: A lightweight model used to convert text into 384-dimensional vectors for ChromaDB.

### Intelligence (The "Mind")
*   **HuggingFace Inference API**: Provides access to **Mistral-7B-Instruct-v0.2**. This LLM is responsible for generating natural language responses and, crucially, deciding which **Tools** to call based on user input.
*   **Regex (Regular Expressions)**: Used in the `IntentDetector` for ultra-fast, deterministic classification of common user actions (e.g., "add to cart") before involving the expensive LLM.

### Infrastructure
*   **SQLite**: Used as the backing store for ChromaDB.
*   **Pickle**: Used to serialize and persist the BM25 index structures.

---

## 3. System Architecture

The system follows a modular "Orchestrator" pattern. The `AssistantHandler` acts as the central brain, coordinating between the User, the Memory (Session), the Intelligence (LLM), and the Skills (Tools).

```mermaid
graph TD
    User[User Client] <--> API[FastAPI Endpoints]
    API <--> Handler[Assistant Handler]
    
    subgraph "Assistant Module"
        Handler <--> Intent[Intent Detector]
        Handler <--> Session[Session Store]
        Handler <--> LLM[HuggingFace LLM]
    end
    
    subgraph "Tools & Skills"
        Handler --> Tools[Tool Executor]
        Tools --> Search[Product Search]
        Tools --> Cart[Cart Manager]
        Tools --> Specs[Spec Q&A]
    end
    
    subgraph "Retrieval Module"
        Search --> Hybrid[Hybrid Searcher]
        Hybrid --> BM25[(BM25 Index)]
        Hybrid --> Vector[(ChromaDB Vector Store)]
    end
```

---

## 4. Module Deep Dive

### 4.1 Retrieval Module (Hybrid Search)

**How it Works:**
The retrieval system solves the "Vocabulary Mismatch Problem". A user might say "sofa" while the catalog says "couch". Vector search catches this. However, vector search can fail on specific model numbers (e.g., "X-200"). BM25 catches that. We combine them using a weighted scoring system.

**Creation Process:**
1.  **Ingestion**: `load_catalog.py` reads the raw CSV.
2.  **Chunking**: Text fields (title, description, specs) are combined into a "document".
3.  **Indexing**:
    *   **Sparse**: The document is tokenized and added to the BM25 corpus.
    *   **Dense**: The document is embedded via `all-MiniLM-L6-v2` and stored in ChromaDB.
4.  **Search**:
    *   Query is sent to both indexes in parallel.
    *   Results are normalized (0-1 scale).
    *   Final Score = `(Vector_Score * 0.7) + (BM25_Score * 0.3)`.

**Code Level Diagram (Search Flow):**
```mermaid
sequenceDiagram
    participant T as Tool
    participant PS as ProductSearcher
    participant B as BM25Index
    participant V as VectorIndex
    
    T->>PS: search("office chair")
    par Parallel Execution
        PS->>B: search("office chair")
        B-->>PS: [Doc A (0.8), Doc B (0.2)]
    and
        PS->>V: search("office chair")
        V-->>PS: [Doc A (0.9), Doc C (0.6)]
    end
    PS->>PS: Normalize & Merge Scores
    PS-->>T: [Doc A (Top), Doc C, Doc B]
```

### 4.2 Assistant Module (The Orchestrator)

**How it Works:**
This module manages the conversation lifecycle. It doesn't just "reply"; it "thinks" and "acts".

**Creation Process:**
1.  **Intent Detection**: We built a `IntentDetector` class with regex patterns. This acts as a router. If the user says "Hi", we don't need an LLM; we just return a greeting. This saves cost and latency.
2.  **Session Management**: The `SessionStore` keeps a history of messages and, critically, a list of `last_shown_products`. This allows the bot to understand "add *that* to cart".
3.  **LLM Integration**: We wrap the HuggingFace API. We feed the LLM a "System Prompt" that defines its personality and a list of "Tools" (JSON definitions) it can call.

**Code Level Diagram (Conversation Loop):**
```mermaid
sequenceDiagram
    participant U as User
    participant H as Handler
    participant I as IntentDetector
    participant S as SessionStore
    participant L as LLM
    
    U->>H: "Show me chairs"
    H->>S: Get History
    H->>I: Detect Intent
    I-->>H: PRODUCT_SEARCH
    
    Note over H,L: Construct Prompt with Tools
    H->>L: Chat(History + Tools)
    L-->>H: FunctionCall("search_products", query="chair")
    
    H->>H: Execute Tool (calls Retrieval Module)
    H->>S: Update last_shown_products
    
    H->>L: Chat(History + ToolResult)
    L-->>H: "I found these chairs..."
    H->>U: Final Response
```

### 4.3 Observability Module

**How it Works:**
To ensure the system is reliable, we track "Events" rather than just text logs.

**Creation Process:**
1.  **Event Definition**: We defined a schema for events (Request, Response, Error).
2.  **Tracking**: The `EventTracker` class appends these JSON objects to `events.jsonl`.
3.  **Metrics**: We can derive metrics (Latency, Intent Distribution) by parsing this file.

---

## 5. Definition of Done (DoD) Compliance Matrix

| Module | Requirement | Implementation Status | Evidence |
| :--- | :--- | :--- | :--- |
| **Retrieval** | Indexes Exist | ✅ DONE | `data/bm25/`, `data/chromadb/` present. |
| | Hybrid Search | ✅ DONE | `ProductSearcher` combines BM25 + Vector. |
| | Async Support | ✅ DONE | All DB calls are `await`ed. |
| **Assistant** | Intent Detection | ✅ DONE | `IntentDetector` covers Search, Cart, Specs. |
| | Context Memory | ✅ DONE | `SessionStore` tracks product history. |
| | Tool Usage | ✅ DONE | LLM calls `search_products` via `tools.py`. |
| **Observability** | Structured Logs | ✅ DONE | `events.jsonl` contains JSON logs. |
| | Documentation | ✅ DONE | `INFRA_FRICTION.md` and this file. |

---

## 6. How to Maintain & Extend

### Adding a New Intent
1.  Open `app/modules/assistant/intents.py` and add the Enum value.
2.  Open `app/modules/assistant/intent_detector.py` and add the Regex pattern.

### Adding a New Tool
1.  Define the function in `app/modules/assistant/tools.py`.
2.  Add the JSON schema to `TOOL_DEFINITIONS` in the same file.
3.  Map the name to the function in `execute_tool`.

### Re-indexing Data
If `products.csv` changes:
1.  Stop the server.
2.  Run `python -m app.modules.catalog_index.load_catalog`.
3.  Restart the server.

---

## 7. Conclusion
The Easymart Chatbot backend is a robust, production-ready foundation. It successfully decouples the "Search" logic from the "Conversation" logic, allowing each to be optimized independently. The use of Hybrid Search ensures high relevance, while the Intent/Tool architecture ensures the bot is actionable, not just chatty.
